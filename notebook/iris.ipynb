{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning framework example\n",
    "\n",
    "This notebook demonstrates how to use the deeplearning API to train and test the model on the [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris).\n",
    "\n",
    "To install the necessary software, use `make deps` in the root directory of the project.  If you don't have make installed or don't want to use it, then use:\n",
    "\n",
    "`pip install -r src/python/requirements.txt`\n",
    "\n",
    "**Note**: it is not necessary to install the `zensols.deeplearn` package to run this notebook.\n",
    "\n",
    "\n",
    "## What is demoed\n",
    "\n",
    "This notebook shows how to create an executor directly.  However, an easier more client friendly facade is available and given in the *mnist* notebook.\n",
    "\n",
    "Also see the the *debug* notebook, which demostrates how to debug a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up notebook environment\n",
    "import sys\n",
    "app_root_dir = '..'\n",
    "sys.path.append(app_root_dir + '/src/python')\n",
    "sys.path.append(app_root_dir + '/test/python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the object factory\n",
    "\n",
    "This creates a factoty that instantiates Python objects using a simple configuration (INI).  This removes much of the complexity of creating and \"hooking up\" all the instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from zensols.config import ExtendedInterpolationEnvConfig as AppConfig\n",
    "from zensols.config import ImportConfigFactory\n",
    "from zensols.deeplearn import TorchConfig\n",
    "from zensols.deeplearn.result import ModelResultGrapher\n",
    "\n",
    "# initialze PyTorch and set the random seed so things are predictable\n",
    "TorchConfig.init()\n",
    "\n",
    "temp_dir = Path('../target')\n",
    "if temp_dir.is_dir():\n",
    "    import shutil\n",
    "    print(f'removing previous results in {temp_dir}')\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "# configure logging\n",
    "logging.basicConfig(format='%(asctime)-15s %(name)s [%(levelname)s]: %(message)s',\n",
    "                    level=logging.WARNING)\n",
    "for name in ['zensols.deeplearn.result',\n",
    "             'zensols.deeplearn.model.facade',\n",
    "             'zensols.deeplearn.batch.stash']:\n",
    "    logging.getLogger(name).setLevel(logging.INFO)\n",
    "\n",
    "# configure the environment\n",
    "config = AppConfig(app_root_dir + '/test-resources/iris/iris.conf',\n",
    "                   env={'app_root': app_root_dir})\n",
    "\n",
    "# create a factoty that instantiates Python objects using a simple configuration (INI)\n",
    "factory = ImportConfigFactory(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model executor\n",
    "\n",
    "Use the factory to create the model executor (see the `executor` section of `test-resources/iris/iris.conf`).  The `write` method gives statistics on the data set that is configured on the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = factory('executor')\n",
    "executor.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the model\n",
    "\n",
    "Every time the executor is told to train, it creates a new model.  It also stores this model to the disk every time the validation loss drops.  The method that controls the creation is `_create_model`, and not meant to be called by the client.  Note this creates a new PyTorch `torch.nn.Module` every time and isn't the same instance used by the executor.\n",
    "\n",
    "In this case, a four deep fully connected network is created and fanned out from the 4 features (from four columns from the CSV file) to 20.  This is then reduce to the output layer having three neurons indicating which type of flower (setosa, versicolor, or virginica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(executor._create_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the model\n",
    "\n",
    "This trains the model on the Iris (flower) data set and prints the results.  The PyTorch model itself is also printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the executor to give us console output\n",
    "executor.progress_bar = True\n",
    "\n",
    "# train the model\n",
    "executor.train()\n",
    "\n",
    "# test the model\n",
    "res = executor.test()\n",
    "\n",
    "# write a summary of the results\n",
    "res.write()\n",
    "\n",
    "# graph the results\n",
    "grapher = ModelResultGrapher('Iris dataset', [15, 5])\n",
    "grapher.plot([res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model facade\n",
    "\n",
    "An easier wasy to use the executor is with a *facade*.  A `ModelFacade` provides easy to use client entry points to the model executor, which trains, validates, tests, saves and loads the model.  Create the facade with a factory, which in turn creates the executor.  The statistics on the data set that is configured on the executor is, by default, printed to standard out.  You can set the `writer` property to `None` on the facade to disable this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from zensols.deeplearn.model import ModelFacade\n",
    "\n",
    "@dataclass\n",
    "class IrisModelFacade(ModelFacade):\n",
    "    def _configure_debug_logging(self):\n",
    "        super()._configure_debug_logging()\n",
    "        logging.getLogger('iris.model').setLevel(logging.DEBUG)\n",
    "        \n",
    "# deallocate the previous executor\n",
    "executor.deallocate()\n",
    "# create the facade\n",
    "facade = IrisModelFacade(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune setting hyperparameters\n",
    "\n",
    "Now that we have our model training and we have evaluated the results, we see the validation loss is very spiky.  This means our learning rate is probably too high as when it moves during stochastic gradient descent it is \"jumping\" too far and back up the error surface.\n",
    "\n",
    "To fix that, let's decrease the learning rate.  We can do that by adjusting the hyperparameters directly on the facade.  In fact, the purpose of the facade is to make changes easily such as this.\n",
    "\n",
    "Notice that the facade prints the output with a correctly configured scroll bar by default.  Output can be disabled by setting the `writer` attribute/initializer parameter to `None`.  The progress bar and columns are set with the `progress_bar` and `progress_bar_col` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of epochs and learning rate, which are both model parameters\n",
    "facade.epochs = 20\n",
    "facade.learning_rate = .01\n",
    "# train and test the model\n",
    "facade.train()\n",
    "facade.test()\n",
    "# display the results in this cell\n",
    "facade.write_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters\n",
    "\n",
    "While we're at it, let's also adjust the drop out, which is a network settings, to see if we can get better results.  Also note that the model converged pretty late indicating we aren't over training, so add more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off output so we can get just the final results later with `write_result`\n",
    "facade.writer = None\n",
    "# set network parameter `dropout` and model settings to achieve better performance\n",
    "facade.dropout = 0.1\n",
    "# set lower learning rate and compensate with epochs in case learning is slower\n",
    "facade.epochs = 1000\n",
    "facade.learning_rate = .005\n",
    "# train and test again\n",
    "facade.train()\n",
    "facade.test()\n",
    "# display the results in this cell\n",
    "facade.write_result()\n",
    "# plot results\n",
    "facade.plot_result()\n",
    "# now since we like our results, save them to disk\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "The executor contains the results from the last run, in additional to saving it.  In our case, we have the same instance of the model we just tested, which contains not only the performance metrics, but the predictions themselves.  Use `get_predictions` to get a Pandas `pd.DataFrame` for the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iris.model import IrisDataPoint\n",
    "\n",
    "# optionally, we can transform the data point instance used, otherwise it defaults to `str`\n",
    "def map_data_point(dp: IrisDataPoint):\n",
    "    \"\"\"Map the data point's Pandas row information (pd.Series) to key/value string.\n",
    "    \n",
    "    :param dp: the data point created by the ``iris_dataset_stash`` as defined in the configuration\n",
    "    \n",
    "    \"\"\"\n",
    "    s = ', '.join(map(lambda x: f'{x[0]}={x[1]}', dp.row.items()))\n",
    "    return dp.row['sepal_length'], dp.row['sepal_width'], dp.row['petal_length'], dp.row['petal_width']\n",
    "facade.get_predictions(column_names=['sepal length', 'sepal width', 'petal length', 'petal width'], transform=map_data_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zensols.persist import dealloc\n",
    "from zensols.deeplearn.model import ModelFacade\n",
    "from pathlib import Path\n",
    "\n",
    "# deallocate the previous facade\n",
    "facade.deallocate()\n",
    "path = Path('../target/iris/results/iris-1.model')\n",
    "# create a new facade wrapped in a deallocation block\n",
    "# (it will be deallocated even in an error generated in the block)\n",
    "with dealloc(ModelFacade.load_from_path(path)) as facade:\n",
    "    facade.write_result()\n",
    "# note that no test results are given since this model was saved during\n",
    "# training after achieving the lowest validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also revive the model as a facade to test, then we'll get the test results\n",
    "with dealloc(ModelFacade.load_from_path(path)) as facade:\n",
    "    facade.writer = None\n",
    "    facade.test()\n",
    "    facade.write_result(include_converged=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
