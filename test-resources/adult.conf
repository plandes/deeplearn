# config

[default]
root_dir = ${env:app_root}
test_resources = ${root_dir}/test-resources
data_dir = ${test_resources}/adult
temporary_dir = ${root_dir}/target/adult
temporary_batch_dir = ${temporary_dir}/batch
results_dir = ${temporary_dir}/results

[cpu_torch_config]
class_name = zensols.deeplearn.TorchConfig
use_gpu = False
data_type = eval({'import': ['torch']}): torch.float32

[gpu_torch_config]
class_name = zensols.deeplearn.TorchConfig
use_gpu = True
data_type = eval({'import': ['torch']}): torch.float32


# data set

[adult_dataset_stash]
class_name = adult.data.AdultDatasetStash
train_path = ${default:data_dir}/adult_train.csv.zip
test_path = ${default:data_dir}/adult_test.csv.zip
dataframe_path = path: ${default:temporary_dir}/df.dat
key_path = path: ${default:temporary_dir}/keys.dat
metadata_path = path: ${default:temporary_dir}/meta.dat
validation_portion = 0.2
split_col = ds_type

[adult_dataset_split_stash]
class_name = zensols.deeplearn.DatasetSplitStash
delegate = instance: adult_dataset_stash
split_container = instance: adult_dataset_stash


# vectorizer

[adult_vectorizer_manager]
class_name = zensols.deeplearn.DataframeFeatureVectorizerManager
torch_config = instance: cpu_torch_config
configured_vectorizers = eval: ()
module_vectorizers = None
prefix = adl_
label_col = eval({'import': ['adult.data']}): adult.data.AdultDatasetStash.LABEL
stash = instance: adult_dataset_stash

[adult_vectorizer_set]
class_name = zensols.deeplearn.FeatureVectorizerManagerSet
names = eval: 'adult_vectorizer_manager'.split()


# persistence

[adult_batch_dataframe_dir_stash]
class_name = zensols.persist.DirectoryStash
path = path: ${default:temporary_batch_dir}/data

[adult_batch_dataframe_stash]
class_name = zensols.deeplearn.DataframeBatchStash
delegate = instance: adult_batch_dataframe_dir_stash
split_stash_container = instance: adult_dataset_stash
data_point_id_sets_path = path: ${default:temporary_batch_dir}/batch-point-keys.dat
vectorizer_manager_set = instance: adult_vectorizer_set
data_point_type = eval({'import': ['zensols.deeplearn']}): zensols.deeplearn.DataframeDataPoint
batch_type = eval({'import': ['zensols.deeplearn']}): zensols.deeplearn.DataframeBatch
decoded_attributes = eval: 'target age sex country'.split()
#decoded_attributes = None
model_torch_config = instance: gpu_torch_config
feature_vectorizer_manager = instance: adult_vectorizer_manager
batch_size = 200
chunk_size = 0
workers = 1
#batch_limit = 10
batch_limit = eval: sys.maxsize

[adult_batch_stash]
class_name = zensols.deeplearn.DatasetSplitStash
delegate = instance: adult_batch_dataframe_stash
split_container = instance: adult_batch_dataframe_stash
