# config

[default]
temporary_dir = ./target
temporary_batch_dir = ${temporary_dir}/batch

[torch_config]
class_name = zensols.deeplearn.TorchConfig
use_gpu = False
data_type = eval({'import': ['torch']}): torch.float64

[gpu_torch_config]
class_name = zensols.deeplearn.TorchConfig
use_gpu = True
data_type = eval({'import': ['torch']}): torch.float16


# vectorizer

[label_vectorizer]
class_name = zensols.deeplearn.CategoryEncodableFeatureVectorizer
categories = eval: ['setosa', 'versicolor', 'virginica']
feature_type = ilabel

[series_vectorizer]
class_name = zensols.deeplearn.SeriesEncodableFeatureVectorizer
feature_type = iseries

[iris_vectorizer_manager]
class_name = zensols.deeplearn.FeatureVectorizerManager
torch_config = instance: torch_config
configured_vectorizers = eval: 'label_vectorizer series_vectorizer'.split()
module_vectorizers = None

[vectorizer_set]
class_name = zensols.deeplearn.FeatureVectorizerManagerSet
names = eval: 'iris_vectorizer_manager'.split()


# persistence

[dataset_stash]
class_name = zensols.deeplearn.stash.DefaultDataframeStash
dataframe_path = path: target/df.dat
key_path = path: target/keys.dat
split_col = ds_type
input_csv_path = path: test-resources/iris.csv

[dataset_split_stash]
class_name = zensols.deeplearn.DatasetSplitStash
delegate = instance: dataset_stash
split_container = instance: dataset_stash

[batch_dataset_dir_stash]
class_name = zensols.persist.stash.DirectoryStash
path = path: ${default:temporary_batch_dir}/data

[feature_subset_batch_dataset_stash]
class_name = zensols.deeplearn.batch.BatchStash
delegate = instance: batch_dataset_dir_stash
split_stash_container = instance: dataset_stash
data_point_id_sets = path: ${default:temporary_batch_dir}/batch-point-keys.dat
vectorizer_manager_set = instance: vectorizer_set
data_point_type = eval({'import': ['iris_domain']}): iris_domain.IrisDataPoint
batch_type = eval({'import': ['iris_domain']}): iris_domain.IrisBatch
decoded_attributes = eval: ['label']
torch_config = instance: gpu_torch_config
batch_size = 7
chunk_size = 0
workers = 0
data_point_id_set_limit = 10

[batch_dataset_stash]
class_name = zensols.deeplearn.batch.BatchStash
delegate = instance: batch_dataset_dir_stash
split_stash_container = instance: dataset_stash
data_point_id_sets = path: ${default:temporary_batch_dir}/batch-point-keys.dat
vectorizer_manager_set = instance: vectorizer_set
data_point_type = eval({'import': ['iris_domain']}): iris_domain.IrisDataPoint
batch_type = eval({'import': ['iris_domain']}): iris_domain.IrisBatch
decoded_attributes = None
torch_config = instance: gpu_torch_config
batch_size = 7
chunk_size = 0
workers = 0
data_point_id_set_limit = 10
