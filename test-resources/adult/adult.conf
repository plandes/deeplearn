# config

[default]
root_dir = ${env:app_root}
test_resources = ${root_dir}/test-resources
data_dir = ${test_resources}/adult
temporary_dir = ${root_dir}/target/adult
temporary_batch_dir = ${temporary_dir}/batch
results_dir = ${temporary_dir}/results

[cpu_torch_config]
class_name = zensols.deeplearn.TorchConfig
use_gpu = False
data_type = eval({'import': ['torch']}): torch.float32

[gpu_torch_config]
class_name = zensols.deeplearn.TorchConfig
use_gpu = True
data_type = eval({'import': ['torch']}): torch.float32


# data set

[adult_dataset_stash]
class_name = adult.data.AdultDatasetStash
train_path = ${default:data_dir}/adult_train.csv.zip
test_path = ${default:data_dir}/adult_test.csv.zip
dataframe_path = path: ${default:temporary_dir}/df.dat
key_path = path: ${default:temporary_dir}/keys.dat
metadata_path = path: ${default:temporary_dir}/meta.dat
validation_portion = 0.3
split_col = ds_type

[adult_dataset_split_stash]
class_name = zensols.dataset.DatasetSplitStash
delegate = instance: adult_dataset_stash
split_container = instance: adult_dataset_stash


# vectorizer

[adult_vectorizer_manager]
class_name = zensols.dataframe.DataframeFeatureVectorizerManager
torch_config = instance: cpu_torch_config
configured_vectorizers = None
module_vectorizers = None
prefix = adl_
label_col = eval({'import': ['adult.data']}): adult.data.AdultDatasetStash.LABEL
stash = instance: adult_dataset_stash

[adult_vectorizer_set]
class_name = zensols.deeplearn.vectorize.FeatureVectorizerManagerSet
names = eval: 'adult_vectorizer_manager'.split()


# persistence

[adult_batch_dataframe_dir_stash]
class_name = zensols.persist.DirectoryStash
path = path: ${default:temporary_batch_dir}/data

[adult_batch_dataframe_stash]
class_name = zensols.dataframe.DataframeBatchStash
delegate = instance: adult_batch_dataframe_dir_stash
split_stash_container = instance: adult_dataset_stash
data_point_id_sets_path = path: ${default:temporary_batch_dir}/batch-point-keys.dat
vectorizer_manager_set = instance: adult_vectorizer_set
data_point_type = eval({'import': ['zensols.dataframe']}): zensols.dataframe.DataframeDataPoint
#data_point_type = eval({'import': ['adult.data']}): adult.data.AdultDataPoint
batch_type = eval({'import': ['zensols.dataframe']}): zensols.dataframe.DataframeBatch
decoded_attributes = eval: set(("""target
		   race sex country education martial_status relationship workclass target occupation
		   age_norm fnlwgt_norm education_num_norm capital_gain_norm capital_loss_norm hours_per_week_norm
		   """).split())
#		   age_norm fnlwgt_norm education_num_norm capital_gain_norm capital_loss_norm hours_per_week_norm
#		   age fnlwgt education_num capital_gain capital_loss hours_per_week
#decoded_attributes = None
model_torch_config = instance: gpu_torch_config
chunk_size = 0
workers = 0
batch_size = 400
batch_limit = eval: sys.maxsize
#batch_size = 10
#batch_limit = 10

[adult_batch_stash]
class_name = zensols.dataset.DatasetSplitStash
delegate = instance: adult_batch_dataframe_stash
split_container = instance: adult_batch_dataframe_stash


# model

[net_settings]
class_name = adult.model.AdultNetworkSettings
torch_config = instance: gpu_torch_config
dataframe_stash = instance: adult_batch_dataframe_stash
dropout = 0.1
input_dropout = None
activation = None
deep_linear_activation = None
middle_features = eval: [2]
last_layer_features = 40
out_features = 2
use_batch_norm = True
debug = False

[model_settings]
class_name = zensols.deeplearn.ModelSettings
path = path: ${default:temporary_dir}/model.pt
learning_rate = 0.0001
# keep all data in GPU memory
batch_iteration = gpu
# number of epochs to train the model
epochs = 120

[executor]
class_name = zensols.deeplearn.ModelExecutor
model_name = Adult
model_settings = instance: model_settings
net_settings = instance: net_settings
dataset_stash = instance: adult_batch_stash
dataset_split_names = eval: 'train val test'.split()
#dataset_split_names = eval: 'test test test'.split()
result_path = path: ${default:results_dir}
